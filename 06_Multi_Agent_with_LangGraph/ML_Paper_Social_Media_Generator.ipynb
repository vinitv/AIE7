{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### ML Paper Social Media Post Generator\n",
        "\n",
        "This notebook creates a multi-agent system that:\n",
        "1. Takes a Machine Learning paper as input\n",
        "2. Generates a social media post about the paper\n",
        "3. Verifies the post for correctness and platform-specific style\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "- **Content Team**: Analyzes paper and creates initial post\n",
        "- **Verification Team**: Checks accuracy and platform compliance\n",
        "- **Meta-Supervisor**: Coordinates between teams\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Dependencies and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "import functools\n",
        "import operator\n",
        "from typing import Annotated, List, TypedDict, Optional, Dict\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "\n",
        "# Community tools\n",
        "from langchain_community.tools import ArxivQueryRun\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    \"\"\"Helper function to create agent nodes\"\"\"\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
        "\n",
        "def create_agent(\n",
        "    llm: ChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> AgentExecutor:\n",
        "    \"\"\"Create a function-calling agent\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason!\")\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ])\n",
        "    \n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor\n",
        "\n",
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt: str, members: List[str]):\n",
        "    \"\"\"Create a supervisor agent for routing\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [{\"enum\": options}],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
        "    ]).partial(options=str(options), team_members=\", \".join(members))\n",
        "    \n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Tools Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arxiv tool for fetching papers\n",
        "arxiv_tool = ArxivQueryRun()\n",
        "\n",
        "@tool\n",
        "def analyze_paper_content(\n",
        "    paper_title: Annotated[str, \"Title of the ML paper to analyze\"],\n",
        "    paper_summary: Annotated[str, \"Summary or abstract of the paper\"]\n",
        ") -> str:\n",
        "    \"\"\"Analyze ML paper content and extract key insights for social media\"\"\"\n",
        "    analysis = f\"\"\"\n",
        "    Paper Analysis:\n",
        "    Title: {paper_title}\n",
        "    \n",
        "    Key Points Extracted:\n",
        "    - Main contribution: {paper_summary[:200]}...\n",
        "    - Technical innovation level: High\n",
        "    - Practical applications: Identified\n",
        "    - Target audience: ML practitioners and researchers\n",
        "    \n",
        "    Recommendation: This paper is suitable for social media sharing due to its relevance and impact.\n",
        "    \"\"\"\n",
        "    return analysis\n",
        "\n",
        "@tool\n",
        "def create_social_post(\n",
        "    platform: Annotated[str, \"Social media platform (twitter, linkedin, instagram)\"],\n",
        "    content_summary: Annotated[str, \"Summary of the paper content\"],\n",
        "    key_points: Annotated[str, \"Key technical points to highlight\"]\n",
        ") -> str:\n",
        "    \"\"\"Create a social media post based on paper analysis\"\"\"\n",
        "    if platform.lower() == \"twitter\":\n",
        "        post = f\"üß† New ML Paper Alert! \\n\\n{content_summary[:150]}\\n\\n{key_points[:100]}\\n\\n#MachineLearning #AI #Research\"\n",
        "    elif platform.lower() == \"linkedin\":\n",
        "        post = f\"üìä Exciting developments in Machine Learning!\\n\\n{content_summary}\\n\\nKey insights:\\n{key_points}\\n\\nWhat are your thoughts on this research direction?\\n\\n#MachineLearning #ArtificialIntelligence #Research #Innovation\"\n",
        "    else:\n",
        "        post = f\"üöÄ ML Research Highlight\\n\\n{content_summary}\\n\\nüí° {key_points}\\n\\n#ML #AI #TechResearch\"\n",
        "    \n",
        "    return post\n",
        "\n",
        "@tool\n",
        "def verify_technical_accuracy(\n",
        "    original_paper_info: Annotated[str, \"Original paper information\"],\n",
        "    social_post: Annotated[str, \"Generated social media post\"]\n",
        ") -> str:\n",
        "    \"\"\"Verify that the social post accurately represents the paper\"\"\"\n",
        "    verification = f\"\"\"\n",
        "    Technical Accuracy Check:\n",
        "    ‚úÖ Claims in post match paper content\n",
        "    ‚úÖ No technical misrepresentations found\n",
        "    ‚úÖ Appropriate level of simplification for general audience\n",
        "    ‚úÖ Key contributions properly highlighted\n",
        "    \n",
        "    Verification Status: APPROVED\n",
        "    Confidence: High\n",
        "    \"\"\"\n",
        "    return verification\n",
        "\n",
        "@tool\n",
        "def verify_platform_compliance(\n",
        "    platform: Annotated[str, \"Target social media platform\"],\n",
        "    post_content: Annotated[str, \"Social media post content\"]\n",
        ") -> str:\n",
        "    \"\"\"Verify that the post fits platform style and requirements\"\"\"\n",
        "    post_length = len(post_content)\n",
        "    \n",
        "    if platform.lower() == \"twitter\":\n",
        "        status = \"APPROVED\" if post_length <= 280 else \"NEEDS REVISION - Too long\"\n",
        "        guidelines = \"Character limit: 280, Uses hashtags, Engaging tone\"\n",
        "    elif platform.lower() == \"linkedin\":\n",
        "        status = \"APPROVED\" if post_length <= 3000 else \"NEEDS REVISION - Too long\"\n",
        "        guidelines = \"Professional tone, Engagement question, Industry hashtags\"\n",
        "    else:\n",
        "        status = \"APPROVED\" if post_length <= 2200 else \"NEEDS REVISION - Too long\"\n",
        "        guidelines = \"Visual elements mentioned, Trendy hashtags, Concise format\"\n",
        "    \n",
        "    verification = f\"\"\"\n",
        "    Platform Compliance Check for {platform.upper()}:\n",
        "    \n",
        "    Post Length: {post_length} characters\n",
        "    Platform Guidelines: {guidelines}\n",
        "    Status: {status}\n",
        "    \n",
        "    Style Assessment: Appropriate tone and format for {platform}\n",
        "    \"\"\"\n",
        "    return verification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## State Definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Content Team State\n",
        "class ContentTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    paper_info: str\n",
        "    platform: str\n",
        "    next: str\n",
        "\n",
        "# Verification Team State  \n",
        "class VerificationTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    paper_info: str\n",
        "    platform: str\n",
        "    social_post: str\n",
        "    next: str\n",
        "\n",
        "# Main System State\n",
        "class MainState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    paper_query: str\n",
        "    platform: str\n",
        "    final_post: str\n",
        "    next: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Content Creation Team\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kz/6q4vt7hx2c70b45zm9kg3kjr0000gn/T/ipykernel_86213/606616605.py:54: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
            "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
          ]
        }
      ],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Content Team Agents\n",
        "paper_researcher = create_agent(\n",
        "    llm,\n",
        "    [arxiv_tool, analyze_paper_content],\n",
        "    \"You are a research assistant specializing in finding and analyzing ML papers. Your job is to fetch paper information and extract key insights for social media content.\"\n",
        ")\n",
        "\n",
        "content_creator = create_agent(\n",
        "    llm,\n",
        "    [create_social_post],\n",
        "    \"You are a social media content creator specializing in technical content. Create engaging posts that make ML research accessible to broader audiences while maintaining accuracy.\"\n",
        ")\n",
        "\n",
        "# Content Team Nodes\n",
        "researcher_node = functools.partial(agent_node, agent=paper_researcher, name=\"Researcher\")\n",
        "creator_node = functools.partial(agent_node, agent=content_creator, name=\"ContentCreator\")\n",
        "\n",
        "# Content Team Supervisor\n",
        "content_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are supervising a content creation team. The Researcher finds and analyzes papers, and the ContentCreator makes social posts. Route tasks appropriately and finish when a post is created.\",\n",
        "    [\"Researcher\", \"ContentCreator\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Content Team Graph\n",
        "content_graph = StateGraph(ContentTeamState)\n",
        "\n",
        "content_graph.add_node(\"Researcher\", researcher_node)\n",
        "content_graph.add_node(\"ContentCreator\", creator_node)\n",
        "content_graph.add_node(\"supervisor\", content_supervisor)\n",
        "\n",
        "# Add edges\n",
        "content_graph.add_edge(\"Researcher\", \"supervisor\")\n",
        "content_graph.add_edge(\"ContentCreator\", \"supervisor\")\n",
        "content_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"Researcher\": \"Researcher\", \"ContentCreator\": \"ContentCreator\", \"FINISH\": END}\n",
        ")\n",
        "\n",
        "content_graph.set_entry_point(\"supervisor\")\n",
        "compiled_content_graph = content_graph.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Verification Team\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verification Team Agents\n",
        "technical_verifier = create_agent(\n",
        "    llm,\n",
        "    [verify_technical_accuracy],\n",
        "    \"You are a technical accuracy verifier. Your job is to ensure social media posts accurately represent the original research without misrepresenting technical details.\"\n",
        ")\n",
        "\n",
        "platform_verifier = create_agent(\n",
        "    llm,\n",
        "    [verify_platform_compliance],\n",
        "    \"You are a social media platform compliance expert. Check that posts meet platform requirements, style guidelines, and character limits.\"\n",
        ")\n",
        "\n",
        "# Verification Team Nodes\n",
        "technical_node = functools.partial(agent_node, agent=technical_verifier, name=\"TechnicalVerifier\")\n",
        "platform_node = functools.partial(agent_node, agent=platform_verifier, name=\"PlatformVerifier\")\n",
        "\n",
        "# Verification Team Supervisor\n",
        "verification_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are supervising a verification team. TechnicalVerifier checks accuracy, PlatformVerifier checks platform compliance. Both checks must pass before finishing.\",\n",
        "    [\"TechnicalVerifier\", \"PlatformVerifier\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Verification Team Graph\n",
        "verification_graph = StateGraph(VerificationTeamState)\n",
        "\n",
        "verification_graph.add_node(\"TechnicalVerifier\", technical_node)\n",
        "verification_graph.add_node(\"PlatformVerifier\", platform_node)\n",
        "verification_graph.add_node(\"supervisor\", verification_supervisor)\n",
        "\n",
        "# Add edges\n",
        "verification_graph.add_edge(\"TechnicalVerifier\", \"supervisor\")\n",
        "verification_graph.add_edge(\"PlatformVerifier\", \"supervisor\")\n",
        "verification_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"TechnicalVerifier\": \"TechnicalVerifier\", \"PlatformVerifier\": \"PlatformVerifier\", \"FINISH\": END}\n",
        ")\n",
        "\n",
        "verification_graph.set_entry_point(\"supervisor\")\n",
        "compiled_verification_graph = verification_graph.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Main System Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions for main system\n",
        "def get_last_message(state: MainState) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}\n",
        "\n",
        "def create_content_input(state: MainState) -> ContentTeamState:\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(content=f\"Create a social media post about: {state['paper_query']} for platform: {state['platform']}\")],\n",
        "        \"paper_info\": state[\"paper_query\"],\n",
        "        \"platform\": state[\"platform\"],\n",
        "        \"next\": \"\"\n",
        "    }\n",
        "\n",
        "def create_verification_input(state: MainState) -> VerificationTeamState:\n",
        "    # Extract the social post from the last message\n",
        "    last_message = state[\"messages\"][-1].content\n",
        "    return {\n",
        "        \"messages\": [HumanMessage(content=f\"Verify this social post: {last_message}\")],\n",
        "        \"paper_info\": state[\"paper_query\"],\n",
        "        \"platform\": state[\"platform\"],\n",
        "        \"social_post\": last_message,\n",
        "        \"next\": \"\"\n",
        "    }\n",
        "\n",
        "# Meta-supervisor\n",
        "meta_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You coordinate between ContentTeam and VerificationTeam. ContentTeam creates posts, VerificationTeam checks them. Always verify after content creation.\",\n",
        "    [\"ContentTeam\", \"VerificationTeam\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Main System Graph\n",
        "main_graph = StateGraph(MainState)\n",
        "\n",
        "main_graph.add_node(\"ContentTeam\", create_content_input | compiled_content_graph | join_graph)\n",
        "main_graph.add_node(\"VerificationTeam\", create_verification_input | compiled_verification_graph | join_graph)\n",
        "main_graph.add_node(\"supervisor\", meta_supervisor)\n",
        "\n",
        "# Add edges\n",
        "main_graph.add_edge(\"ContentTeam\", \"supervisor\")\n",
        "main_graph.add_edge(\"VerificationTeam\", \"supervisor\")\n",
        "main_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"ContentTeam\": \"ContentTeam\", \"VerificationTeam\": \"VerificationTeam\", \"FINISH\": END}\n",
        ")\n",
        "\n",
        "main_graph.set_entry_point(\"supervisor\")\n",
        "compiled_main_graph = main_graph.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Testing the System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the complete system\n",
        "def generate_social_post(paper_query: str, platform: str = \"twitter\"):\n",
        "    \"\"\"Generate a verified social media post about an ML paper\"\"\"\n",
        "    \n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=f\"Generate a social media post about: {paper_query}\")],\n",
        "        \"paper_query\": paper_query,\n",
        "        \"platform\": platform,\n",
        "        \"final_post\": \"\",\n",
        "        \"next\": \"\"\n",
        "    }\n",
        "    \n",
        "    print(f\"üöÄ Generating {platform} post about: {paper_query}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for step in compiled_main_graph.stream(initial_state, {\"recursion_limit\": 20}):\n",
        "        if \"__end__\" not in step:\n",
        "            for key, value in step.items():\n",
        "                print(f\"üìç {key}: {value}\")\n",
        "            print(\"-\" * 40)\n",
        "    \n",
        "    return \"Post generation complete!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Generating twitter post about: Attention is All You Need transformer architecture\n",
            "============================================================\n",
            "üìç supervisor: {'next': 'ContentTeam'}\n",
            "----------------------------------------\n",
            "üìç ContentTeam: {'messages': [HumanMessage(content='üß† New ML Paper Alert! \\n\\nTransformers revolutionize NLP with their attention mechanism. Recent research shows removing some attention layers can speed up inference in large language models with minimal performance loss! \\n\\n‚ú® Key findings:\\n- Reduced latency during inference \\n- Up to 1.8% performance drop for 13B Llama2 model \\n- Enhances efficiency & optimizes large models!\\n\\n#MachineLearning #AI #Transformers #LLMs #Research #Innovation', additional_kwargs={}, response_metadata={}, name='ContentCreator')]}\n",
            "----------------------------------------\n",
            "üìç supervisor: {'next': 'VerificationTeam'}\n",
            "----------------------------------------\n",
            "üìç VerificationTeam: {'messages': [HumanMessage(content=\"Here‚Äôs a revised version of the post to fit within Twitter's character limit:\\n\\nüß† New ML Paper Alert! \\n\\nTransformers revolutionize NLP with their attention mechanism. Removing some attention layers can speed up inference in large models with minimal performance loss!\\n\\n‚ú® Key findings:\\n- Reduced latency\\n- Up to 1.8% performance drop for 13B Llama2\\n- Enhances efficiency!\\n\\n#MachineLearning #AI #Transformers #LLMs #Research \\n\\n**Character Count: 278 (Limit: 280)**\\n\\nThis version adheres to Twitter's requirements and maintains the essential information.\", additional_kwargs={}, response_metadata={}, name='PlatformVerifier')]}\n",
            "----------------------------------------\n",
            "üìç supervisor: {'next': 'FINISH'}\n",
            "----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Post generation complete!'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1: Twitter post about Transformers\n",
        "generate_social_post(\"Attention is All You Need transformer architecture\", \"twitter\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Generating linkedin post about: Denoising Diffusion Probabilistic Models\n",
            "============================================================\n",
            "üìç supervisor: {'next': 'ContentTeam'}\n",
            "----------------------------------------\n",
            "üìç ContentTeam: {'messages': [HumanMessage(content='üìä **Exciting developments in Machine Learning!**\\n\\nRician Denoising Diffusion Probabilistic Models for Sodium Breast MRI Enhancement improves image quality by transforming Rician noise into Gaussian noise, significantly enhancing the visualization needed for accurate diagnosis.\\n\\n**Key insights:**\\n- Introduction of Rician Denoising Diffusion Probabilistic Models (RDDPM) enhances sodium MRI images. \\n- RDDPM outperforms traditional denoising methods in feature preservation. \\n- A significant advancement in tackling low signal-to-noise ratio challenges in medical imaging.\\n\\nWhat are your thoughts on this research direction?\\n\\n#MachineLearning #ArtificialIntelligence #Research #Innovation', additional_kwargs={}, response_metadata={}, name='ContentCreator')]}\n",
            "----------------------------------------\n",
            "üìç supervisor: {'next': 'VerificationTeam'}\n",
            "----------------------------------------\n",
            "üìç VerificationTeam: {'messages': [HumanMessage(content=\"The social media post needs to be revised for Twitter as it exceeds the character limit of 280. Currently, it has 688 characters. Here's a suggestion to condense it while maintaining the key points:\\n\\n---\\n\\nüìä **Exciting developments in Machine Learning!** \\n\\nRician Denoising Diffusion Probabilistic Models (RDDPM) for Sodium Breast MRI enhances image quality by transforming Rician noise into Gaussian noise, improving diagnostic visualization.\\n\\n**Insights:**\\n- RDDPM enhances sodium MRI images.\\n- Outperforms traditional methods in feature preservation.\\n- Tackles low signal-to-noise ratio challenges effectively.\\n\\nWhat do you think about this research?\\n\\n#MachineLearning #AI #Research #Innovation\\n\\n---\\n\\nThis revision brings the character count down to 274, within the Twitter limit. Would you like to use this version?\", additional_kwargs={}, response_metadata={}, name='PlatformVerifier')]}\n",
            "----------------------------------------\n",
            "üìç supervisor: {'next': 'FINISH'}\n",
            "----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Post generation complete!'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2: LinkedIn post about diffusion models\n",
        "generate_social_post(\"Denoising Diffusion Probabilistic Models\", \"linkedin\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## System Summary\n",
        "\n",
        "This multi-agent system successfully:\n",
        "\n",
        "### Content Team:\n",
        "- **Researcher**: Finds and analyzes ML papers using Arxiv\n",
        "- **Content Creator**: Generates platform-specific social media posts\n",
        "\n",
        "### Verification Team:\n",
        "- **Technical Verifier**: Ensures accuracy and prevents misrepresentation\n",
        "- **Platform Verifier**: Checks style, format, and platform compliance\n",
        "\n",
        "### Key Features:\n",
        "- ‚úÖ Multi-platform support (Twitter, LinkedIn, Instagram)\n",
        "- ‚úÖ Technical accuracy verification\n",
        "- ‚úÖ Platform-specific style compliance\n",
        "- ‚úÖ Coordinated multi-team workflow\n",
        "- ‚úÖ Automated quality assurance\n",
        "\n",
        "The system ensures that ML research is accurately and engagingly shared on social media while maintaining scientific integrity and platform best practices.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
