{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\" id=\"heading\">OpenAI Agents SDK - AIM</h1>\n",
    "\n",
    "In this notebook, we'll go over some of the key features of the OpenAI Agents SDK - as explored through a notebook-ified version of their [Research Bot](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to run this cell if you're running this notebook locally. \n",
    "\n",
    "#!pip install -qU openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nest Async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "As may be expected, the primary thing we'll do in the Agents SDK is construct Agents!\n",
    "\n",
    "Agents are constructed with a few basic properties:\n",
    "\n",
    "- A prompt, which OpenAI is using the language \"instruction\" for, that determines the behaviour or goal of the Agent\n",
    "- A model, the \"brain\" of the Agent\n",
    "\n",
    "They also typically include an additional property: \n",
    "\n",
    "- Tool(s) that equip the Agent with things it can use to get stuff done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Planner Agent\n",
    "\n",
    "Let's start by creating our \"Planner Agent\" - which will come up with the initial set of search terms that should answer a query provided by the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent\n",
    "\n",
    "PLANNER_PROMPT = (\n",
    "    \"You are a helpful research assistant. Given a query, come up with a set of web searches to perform\" \n",
    "    \"to best answer the query. Output between 5 and 20 terms to query for.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the data models that our Planner Agent will use to structure its output. We'll create:\n",
    "\n",
    "1. `WebSearchItem` - A model for individual search items, containing the search query and reasoning\n",
    "2. `WebSearchPlan` - A container model that holds a list of search items\n",
    "\n",
    "These Pydantic models will help ensure our agent returns structured data that we can easily process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query.\"\n",
    "\n",
    "    query: str\n",
    "    \"The search term to use for the web search.\"\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"\"\"A list of web searches to perform to best answer the query.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Planner Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `PLANNER_PROMPT` and will output structured data in the form of our WebSearchPlan model. We're using the GPT-4o model for this agent to ensure high-quality search term generation.\n",
    "\n",
    "> NOTE: When we provide an `output_type` - the model will return a [structured response](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=PLANNER_PROMPT,\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Question #1:\n",
    "\n",
    "Why is it important to provide a structured response template? (As in: Why are structured outputs helpful/preferred in Agentic workflows?)\n",
    "\n",
    "\n",
    "##### ✅ Answer:\n",
    "Structured response templates are crucial because they make agent communication reliable and predictable. When agents work together, structured outputs ensure each agent gets data in the exact format it expects, eliminating confusion and errors that can happen with free-form text.\n",
    "This approach also makes it easier to connect agents with other systems and tools. APIs and databases can directly use structured data without complex parsing, making the whole system more stable and easier to maintain.\n",
    "For users, structured outputs mean consistent, well-organized results that can be displayed in useful formats like tables and charts. Users get clear information instead of unpredictable text responses.\n",
    "In the research bot example, the WebSearchPlan structure ensures the Planner Agent always returns search items with specific fields, the Search Agent can process them reliably, and the Writer Agent gets organized data to work with. This turns a complex text parsing problem into a simple, reliable data flow between agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create Search Agent\n",
    "\n",
    "Now we'll create our Search Agent, which will be responsible for executing web searches based on the terms generated by the Planner Agent. This agent will take each search query, perform a web search using the `WebSearchTool`, and then summarize the results in a concise format.\n",
    "\n",
    "> NOTE: We are using the `WebSearchTool`, a hosted tool that can be used as part of an `OpenAIResponsesModel` as outlined in the [documentation](https://openai.github.io/openai-agents-python/tools/). This is based on the tools available through OpenAI's new [Responses API](https://openai.com/index/new-tools-for-building-agents/).\n",
    "\n",
    "The `SEARCH_PROMPT` below instructs the agent to create brief, focused summaries of search results. These summaries are designed to be 2-3 paragraphs, under 300 words, and capture only the essential information without unnecessary details. The goal is to provide the Writer Agent with clear, distilled information that can be efficiently synthesized into the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PROMPT = (\n",
    "    \"You are a research assistant. Given a search term, you search the web for that term and\"\n",
    "    \"produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300\"\n",
    "    \"words. Capture the main points. Write succinctly, no need to have complete sentences or good\"\n",
    "    \"grammar. This will be consumed by someone synthesizing a report, so its vital you capture the\"\n",
    "    \"essence and ignore any fluff. Do not include any additional commentary other than the summary\"\n",
    "    \"itself.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Search Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `SEARCH_PROMPT` and will utilize the `WebSearchTool` to perform web searches. We're configuring it with `tool_choice=\"required\"` to ensure it always uses the search tool when processing requests.\n",
    "\n",
    "> NOTE: We can, as demonstrated, indicate how we want our model to use tools. You can read more about that at the bottom of the page [here](https://openai.github.io/openai-agents-python/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=SEARCH_PROMPT,\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #2: \n",
    "\n",
    "What other tools are supported in OpenAI's Responses API?\n",
    "\n",
    "##### ✅ Answer:\n",
    "The OpenAI Agents SDK supports three main classes of tools:\n",
    "\n",
    "1.  **Hosted tools**: These are tools that run on OpenAI's servers. Examples include:\n",
    "    * `WebSearchTool`: for searching the web.\n",
    "    * `FileSearchTool`: for retrieving information from OpenAI Vector Stores.\n",
    "    * `ComputerTool`: for automating computer tasks.\n",
    "    * `CodeInterpreterTool`: for executing code in a sandboxed environment.\n",
    "    * `HostedMCPTool`: for exposing tools from a remote Model Context Protocol (MCP) server.\n",
    "    * `ImageGenerationTool`: for generating images.\n",
    "    * `LocalShellTool`: for running shell commands.\n",
    "\n",
    "2.  **Function tools**: This allows you to wrap any Python function as a tool for the agent to use.\n",
    "\n",
    "3.  **Agents as tools**: This enables an agent to be used as a tool, allowing for more complex multi-agent workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create Writer Agent\n",
    "\n",
    "Finally, we'll create our Writer Agent, which will synthesize all the research findings into a comprehensive report. This agent takes the original query and the research summaries from the Search Agent, then produces a structured report with follow-up questions.\n",
    "\n",
    "The Writer Agent will:\n",
    "1. Create an outline for the report structure\n",
    "2. Generate a detailed markdown report (5-10 pages)\n",
    "3. Provide follow-up questions for further research\n",
    "\n",
    "We'll define the prompt for this agent in the next cell. This prompt will instruct the Writer Agent on how to synthesize research findings into a comprehensive report with follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research \"\n",
    "    \"assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique questions that would help extend \"\n",
    "    \"this research. Do not repeat questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #1: \n",
    "\n",
    "This prompt is quite generic - modify this prompt to produce a report that is more personalized to either your personal preference, or more appropriate for a specific use case (eg. law domain research)\n",
    "\n",
    "##### ✅ Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (    \"You are a senior academic researcher with expertise in multiple disciplines, tasked with writing a \"\n",
    "    \"comprehensive research report. You will be provided with the original query and initial research \"\n",
    "    \"findings from a research assistant.\\n\\n\"\n",
    "    \"Your report should follow academic standards with:\\n\"\n",
    "    \"1. A clear executive summary\\n\"\n",
    "    \"2. Methodology overview of the research approach\\n\"\n",
    "    \"3. Main findings organized by themes\\n\"\n",
    "    \"4. Critical analysis and synthesis of the evidence\\n\"\n",
    "    \"5. Limitations and potential biases in the research\\n\"\n",
    "    \"6. Practical implications and recommendations\\n\"\n",
    "    \"7. Conclusions\\n\\n\"\n",
    "    \"Write in an academic tone with proper citations where relevant. The report should be in markdown \"\n",
    "    \"format, 5-10 pages of detailed content (at least 1000 words). Include data, statistics, and \"\n",
    "    \"evidence-based conclusions.\\n\\n\"\n",
    "    \"For follow-up questions, provide exactly 5 research questions that would advance the field's \"\n",
    "    \"understanding of this topic, focusing on gaps in current knowledge or methodological improvements.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will synthesize all the research findings into a comprehensive report. We're configuring it with the `ReportData` output type to structure the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"\"\"A short 2-3 sentence summary of the findings.\"\"\"\n",
    "\n",
    "    markdown_report: str\n",
    "    \"\"\"The final report\"\"\"\n",
    "\n",
    "    follow_up_questions: list[str]\n",
    "    \"\"\"Suggested topics to research further\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will take the original query and research summaries, then synthesize them into a comprehensive report with follow-up questions. We've defined a custom output type called `ReportData` that structures the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=WRITER_PROMPT,\n",
    "    model=\"o3-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #3: \n",
    "\n",
    "Why are we electing to use a reasoning model for writing our report?\n",
    "##### ✅ Answer:\n",
    "We're using the o3-mini reasoning model for the writer agent because writing a good report is a complex task that needs deep thinking. The writer has to take multiple search results and combine them into one coherent report, figure out which information is most important, and organize everything in a logical way. The reasoning model can handle this kind of multi-step thinking better than simpler models. It can also produce consistent quality across all parts of the report - the summary, the main content, and the follow-up questions. The planner and search agents use simpler models because their jobs are more basic - just planning what to search for and summarizing individual search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create Utility Classes \n",
    "\n",
    "We'll define utility classes to help with displaying progress and managing the research workflow. The Printer class below will provide real-time updates on the research process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Printer class provides real-time progress updates during the research process. It uses Rich's Live display to show dynamic content with spinners for in-progress items and checkmarks for completed tasks. The class maintains a dictionary of items with their completion status and can selectively hide checkmarks for specific items. This creates a clean, interactive console experience that keeps the user informed about the current state of the research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from rich.console import Console, Group\n",
    "from rich.live import Live\n",
    "from rich.spinner import Spinner\n",
    "\n",
    "class Printer:\n",
    "    def __init__(self, console: Console):\n",
    "        self.live = Live(console=console)\n",
    "        self.items: dict[str, tuple[str, bool]] = {}\n",
    "        self.hide_done_ids: set[str] = set()\n",
    "        self.live.start()\n",
    "\n",
    "    def end(self) -> None:\n",
    "        self.live.stop()\n",
    "\n",
    "    def hide_done_checkmark(self, item_id: str) -> None:\n",
    "        self.hide_done_ids.add(item_id)\n",
    "\n",
    "    def update_item(\n",
    "        self, item_id: str, content: str, is_done: bool = False, hide_checkmark: bool = False\n",
    "    ) -> None:\n",
    "        self.items[item_id] = (content, is_done)\n",
    "        if hide_checkmark:\n",
    "            self.hide_done_ids.add(item_id)\n",
    "        self.flush()\n",
    "\n",
    "    def mark_item_done(self, item_id: str) -> None:\n",
    "        self.items[item_id] = (self.items[item_id][0], True)\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        renderables: list[Any] = []\n",
    "        for item_id, (content, is_done) in self.items.items():\n",
    "            if is_done:\n",
    "                prefix = \"✅ \" if item_id not in self.hide_done_ids else \"\"\n",
    "                renderables.append(prefix + content)\n",
    "            else:\n",
    "                renderables.append(Spinner(\"dots\", text=content))\n",
    "        self.live.update(Group(*renderables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a ResearchManager class that will orchestrate the research process. This class will:\n",
    "1. Plan searches based on the query\n",
    "2. Perform those searches to gather information\n",
    "3. Write a comprehensive report based on the gathered information\n",
    "4. Display progress using our Printer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from agents import Runner, custom_span, gen_trace_id, trace\n",
    "\n",
    "class ResearchManager:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        self.printer = Printer(self.console)\n",
    "\n",
    "    async def run(self, query: str) -> None:\n",
    "        trace_id = gen_trace_id()\n",
    "        with trace(\"Research trace\", trace_id=trace_id):\n",
    "            self.printer.update_item(\n",
    "                \"trace_id\",\n",
    "                f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "\n",
    "            self.printer.update_item(\n",
    "                \"starting\",\n",
    "                \"Starting research...\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "            search_plan = await self._plan_searches(query)\n",
    "            search_results = await self._perform_searches(search_plan)\n",
    "            report = await self._write_report(query, search_results)\n",
    "\n",
    "            final_report = f\"Report summary\\n\\n{report.short_summary}\"\n",
    "            self.printer.update_item(\"final_report\", final_report, is_done=True)\n",
    "\n",
    "            self.printer.end()\n",
    "\n",
    "        print(\"\\n\\n=====REPORT=====\\n\\n\")\n",
    "        print(f\"Report: {report.markdown_report}\")\n",
    "        print(\"\\n\\n=====FOLLOW UP QUESTIONS=====\\n\\n\")\n",
    "        unique_questions = []\n",
    "        seen = set()\n",
    "        \n",
    "        for question in report.follow_up_questions:\n",
    "            if question not in seen:\n",
    "                unique_questions.append(question)\n",
    "                seen.add(question)\n",
    "        \n",
    "        for i, question in enumerate(unique_questions, 1):\n",
    "            print(f\"{i}. {question}\")\n",
    "\n",
    "    async def _plan_searches(self, query: str) -> WebSearchPlan:\n",
    "        self.printer.update_item(\"planning\", \"Planning searches...\")\n",
    "        result = await Runner.run(\n",
    "            planner_agent,\n",
    "            f\"Query: {query}\",\n",
    "        )\n",
    "        self.printer.update_item(\n",
    "            \"planning\",\n",
    "            f\"Will perform {len(result.final_output.searches)} searches\",\n",
    "            is_done=True,\n",
    "        )\n",
    "        return result.final_output_as(WebSearchPlan)\n",
    "\n",
    "    async def _perform_searches(self, search_plan: WebSearchPlan) -> list[str]:\n",
    "        with custom_span(\"Search the web\"):\n",
    "            self.printer.update_item(\"searching\", \"Searching...\")\n",
    "            num_completed = 0\n",
    "            max_concurrent = 5\n",
    "            results = []\n",
    "            \n",
    "            for i in range(0, len(search_plan.searches), max_concurrent):\n",
    "                batch = search_plan.searches[i:i+max_concurrent]\n",
    "                tasks = [asyncio.create_task(self._search(item)) for item in batch]\n",
    "                \n",
    "                for task in asyncio.as_completed(tasks):\n",
    "                    try:\n",
    "                        result = await task\n",
    "                        if result is not None:\n",
    "                            results.append(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Search error: {e}\")\n",
    "                        \n",
    "                    num_completed += 1\n",
    "                    self.printer.update_item(\n",
    "                        \"searching\", f\"Searching... {num_completed}/{len(search_plan.searches)} completed\"\n",
    "                    )\n",
    "            \n",
    "            self.printer.mark_item_done(\"searching\")\n",
    "            return results\n",
    "\n",
    "    async def _search(self, item: WebSearchItem) -> str | None:\n",
    "        input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "        try:\n",
    "            result = await Runner.run(\n",
    "                search_agent,\n",
    "                input,\n",
    "            )\n",
    "            return str(result.final_output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{item.query}': {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _write_report(self, query: str, search_results: list[str]) -> ReportData:\n",
    "        self.printer.update_item(\"writing\", \"Thinking about report...\")\n",
    "        input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "        \n",
    "        result = Runner.run_streamed(\n",
    "            writer_agent,\n",
    "            input,\n",
    "        )\n",
    "        \n",
    "        update_messages = [\n",
    "            \"Thinking about report...\",\n",
    "            \"Planning report structure...\",\n",
    "            \"Writing outline...\",\n",
    "            \"Creating sections...\",\n",
    "            \"Cleaning up formatting...\",\n",
    "            \"Finalizing report...\",\n",
    "            \"Finishing report...\",\n",
    "        ]\n",
    "\n",
    "        last_update = time.time()\n",
    "        next_message = 0\n",
    "        \n",
    "        async for event in result.stream_events():\n",
    "            if time.time() - last_update > 5 and next_message < len(update_messages):\n",
    "                self.printer.update_item(\"writing\", update_messages[next_message])\n",
    "                next_message += 1\n",
    "                last_update = time.time()\n",
    "\n",
    "        self.printer.mark_item_done(\"writing\")\n",
    "        return result.final_output_as(ReportData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #2:\n",
    "\n",
    "Convert the above flow into a flowchart style image (software of your choosing, but if you're not sure which to use try [Excallidraw](https://excalidraw.com/)) that outlines how the different Agents interact with each other. \n",
    "\n",
    "> HINT: Cursor's AI (CMD+L or CTRL+L on Windows) would be a helpful way to get a basic diagram that you can add more detail to!\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "\n",
    "![Flowchart](./img/flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Running Our Agent\n",
    "\n",
    "Now let's run our agent! The main function below will prompt the user for a research topic, then pass that query to our ResearchManager to handle the entire research process. The ResearchManager will: \n",
    "\n",
    "1. Break down the query into search items\n",
    "2. Search for information on each item\n",
    "3. Write a comprehensive report based on the search results\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    query = input(\"What would you like to research? \")\n",
    "    await ResearchManager().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fe0c7bec68466f8efdb87310a8524b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====REPORT=====\n",
      "\n",
      "\n",
      "Report: # Comprehensive Research Report on Flying Cars\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Flying cars, primarily envisioned as electric vertical take-off and landing (eVTOL) vehicles, symbolize a transformative potential in urban mobility. Advances in technology, regulatory evolution, and strategic investments are converging to shift these vehicles from a conceptual innovation to a tangible market reality. This report examines the state-of-the-art technological developments, the emerging regulatory frameworks, and the multidimensional challenges that underpin the integration of flying cars into contemporary transportation systems. While the promise of reduced congestion and rapid commuter transit is compelling, critical challenges related to air traffic management, safety, cybersecurity, energy consumption, and infrastructure need concerted attention for widespread adoption (Reuters, 2025; AP, 2024). \n",
      "\n",
      "## Methodology Overview\n",
      "\n",
      "The research approach of this report is based on a systematic review of secondary sources including news articles, regulatory announcements, company releases, and industry reports from reputable sources such as Reuters, AP, CNN, and specialized technological journals. The methodology involved the following steps:\n",
      "\n",
      "1. **Literature Review:** Extensive examination of published articles and research snippets focusing on the technical, regulatory, and economic dimensions of flying cars.\n",
      "\n",
      "2. **Thematic Analysis:** Identification and categorization of key themes including technology innovation, safety and reliability, regulatory framework, infrastructure development, and economic feasibility.\n",
      "\n",
      "3. **Comparative Analysis:** Evaluation of different models and prototypes from companies like Alef Aeronautics, Klein Vision, Joby Aviation, and Hyundai's Supernal division to understand performance metrics, price range, and market readiness.\n",
      "\n",
      "4. **Data Synthesis:** Integration of statistical data where available, such as ranges, speeds, and projected timelines, with qualitative insights from regulatory announcements and expert analyses.\n",
      "\n",
      "5. **Critical Discussion:** Synthesis of evidence to identify gaps in the current knowledge and potential biases in data collection, especially given the media-centric nature of many sources.\n",
      "\n",
      "This multi-pronged methodology ensures a comprehensive analysis while highlighting the most impactful trends in the realm of urban air mobility.\n",
      "\n",
      "## Main Findings Organized by Themes\n",
      "\n",
      "### 1. Technological Innovations\n",
      "\n",
      "Recent advances in flying car technology have been marked by significant progress in propulsion systems, battery technology, autonomous navigation, and safety redundancies:\n",
      "\n",
      "- **Propulsion and Battery Technology:** Most modern flying cars are powered by electric motors combined with innovative battery technologies such as solid-state batteries and hydrogen fuel cells. For example, the Alef Aeronautics Model A and Klein Vision AirCar have introduced designs that enable both road usage and aerial flight, leveraging electric power for vertical take-off and landing (CNN, 2023; Wikipedia, 2022).\n",
      "\n",
      "- **Design and Versatility:** Several models, such as the PAL-V Liberty and AeroMobil 4.0, illustrate how designers are integrating automotive and aviation features. These vehicles typically feature retractable wings and distributed propulsion systems designed to maximize stability and efficiency (Wikipedia, n.d.; Forbes, 2020).\n",
      "\n",
      "- **Autonomous Navigation and Safety Systems:** The integration of advanced sensors (such as lidar, radar, and GPS) with artificial intelligence underpins the autonomous capabilities of eVTOLs. Redundant systems are being developed to ensure safe operation even during component failures, a crucial aspect as these vehicles transition from test prototypes to commercial use (Science News Today, n.d.; Topspeed.com, n.d.).\n",
      "\n",
      "### 2. Regulatory Frameworks and Policy Evolution\n",
      "\n",
      "The regulatory landscape for flying cars is in rapid evolution, with both federal and state agencies taking significant steps to accommodate this emerging technology:\n",
      "\n",
      "- **FAA and International Regulations:** The FAA has introduced new categories, such as the \"powered-lift aircraft,\" to streamline certification processes for air taxis and flying cars. These measures, accompanied by pilot training requirements and updated safety standards, mark a shift in regulatory focus (AP, 2024; Reuters, 2025).\n",
      "\n",
      "- **State-Level Innovations:** Legislation in states like New Hampshire and Minnesota has begun to address the dual nature of roadable aircraft. With laws such as the Jetson Bill, vehicles can be legally driven on roads while taking off and landing only at designated airfields (Forbes, 2020; Flyingmag.com, 2024).\n",
      "\n",
      "- **International Development:** Notably, countries such as China and Slovakia have advanced through their own certification processes. China's EHang, having received Air Operator Certificates for its eVTOL vehicles, demonstrates that a coordinated international approach may further facilitate the adoption of flying cars (CNEVPost, n.d.).\n",
      "\n",
      "### 3. Safety and Cybersecurity Challenges\n",
      "\n",
      "Safety is paramount in a domain where operational failures can lead to catastrophic outcomes:\n",
      "\n",
      "- **Air Traffic Management (ATM):** Integrating flying cars into congested urban airspace necessitates advanced traffic management systems. New models must operate in a seamlessly integrated network with current aviation systems to avoid collisions and maintain orderly flight patterns (TopSpeed.com, n.d.).\n",
      "\n",
      "- **Redundancy and System Reliability:** Developing fault-tolerant designs—with backup propulsion and control systems—is essential. Aircraft failures could have severe implications, mandating innovations that ensure reliable performance under adverse conditions (Science News Today, n.d.).\n",
      "\n",
      "- **Cybersecurity Concerns:** Given the heavy reliance on software and autonomous systems, cybersecurity emerges as a critical challenge. Protecting these vehicles from hacking and ensuring secure communications is necessary to mitigate risks from unauthorized control (Science News Today, n.d.).\n",
      "\n",
      "### 4. Economic and Societal Implications\n",
      "\n",
      "The economic landscape for flying cars is diverse, reflecting both high-end luxury markets and potential mass-market applications in the future:\n",
      "\n",
      "- **Price Range and Market Positioning:** Current models vary widely in price—from the Jetson ONE at approximately $98,000 to luxury models like the Klein Vision AirCar, which could range between $800,000 and $1 million. These price points suggest an initial market niche primarily targeting affluent consumers (Axios, 2023; Simple Flying, n.d.).\n",
      "\n",
      "- **Urban Air Mobility and Infrastructure:** The deployment of flying cars will demand significant investments in infrastructure, including vertiports, charging stations, and dedicated air corridors. For example, projects in Dubai and US cities like New York and Los Angeles underscore the scale of transformation required in urban planning (Reuters, 2025; Axios, 2022).\n",
      "\n",
      "- **Environmental Impact:** Although electric propulsion promises reduced emissions during operation, the overall environmental footprint must be considered. Energy demands for vertical takeoff and landing, as well as manufacturing impacts, could mitigate some ecological benefits (American Progress, n.d.).\n",
      "\n",
      "## Critical Analysis and Synthesis\n",
      "\n",
      "The convergence of automotive and aviation technologies in flying cars represents an important milestone in transportation innovation. However, the realization of their full potential is contingent upon addressing several key challenges:\n",
      "\n",
      "- **Safety and Reliability Versus Innovation:** The technological strides made in propulsion, battery, and autonomous navigation systems are remarkable. Nevertheless, the safety assurances required by regulatory bodies and the public remain a significant hurdle. The necessity for foolproof safety systems has kept some technologies in the demonstrative phase, and further research should focus on establishing redundant fail-safe mechanisms (Science News Today, n.d.).\n",
      "\n",
      "- **Regulatory Adaptation and International Standards:** While individual regulatory bodies have initiated policies to facilitate the evolution of flying cars, a disjointed regulatory environment across regions could impede global adoption. Harmonizing standards internationally is crucial, and future research should address the creation of supranational regulatory frameworks (Trifactor.sg, n.d.).\n",
      "\n",
      "- **Infrastructure and Urban Planning:** Practical implementation extends beyond aircraft certification. The construction of vertiports, charging stations, and updating urban air traffic management systems involves significant capital expenditure and policy integration. Existing urban infrastructures must be overhauled to coexist with aerial mobility solutions without compromising ground transportation safety (Axios, 2022).\n",
      "\n",
      "- **Economic Viability and Public Adoption:** The initial high cost of these vehicles makes them luxury commodities. As production scales and technology matures, costs are expected to decrease. However, market penetration will depend on public trust in the technology’s safety and efficiency. Parallel investments in public education and rigorous safety demonstrations are necessary to foster wider acceptance (Simple Flying, n.d.). \n",
      "\n",
      "## Limitations and Potential Biases\n",
      "\n",
      "Several limitations are inherent in this research:\n",
      "\n",
      "1. **Reliance on Media Reports:** Much of the data and qualitative analysis is derived from media sources and preliminary reports, which can be biased towards optimistic projections or limited by the lack of peer-reviewed analysis.\n",
      "\n",
      "2. **Evolving Regulatory Landscape:** The regulatory frameworks for flying cars are still in flux. Current policies may not fully capture future changes, and the rapid pace of technological innovation may outstrip policy development.\n",
      "\n",
      "3. **Geographical Bias:** The majority of available information originates from North America, Europe, and select parts of Asia. Broader global perspectives, especially from emerging markets, remain less represented in the current literature.\n",
      "\n",
      "4. **Technological Uncertainty:** Given that many flying car prototypes have yet to reach mass production, technical performance data are often based on controlled tests rather than real-world scenarios. This introduces uncertainties in scalability and long-term reliability.\n",
      "\n",
      "## Practical Implications and Recommendations\n",
      "\n",
      "Given the potential of flying cars to revolutionize urban mobility, several practical recommendations can be drawn:\n",
      "\n",
      "- **Investment in Infrastructure:** Governments and private investors should prioritize the development of supportive infrastructure, including vertiports and advanced air traffic control systems. Pilot projects in metropolitan areas can serve as test beds for urban air mobility (Reuters, 2025).\n",
      "\n",
      "- **Collaborative Regulatory Development:** Regulatory bodies, industry leaders, and academic researchers must collaborate to establish harmonized standards and safety protocols. This cooperation is essential to ensure that technological advancements are matched by corresponding regulatory frameworks (AP, 2024).\n",
      "\n",
      "- **Focus on Safety Research:** Additional research and investment in fault-tolerant systems and cybersecurity measures are essential. Grants and public-private partnerships should be encouraged to advance studies in autonomous safety, sensor fusion technology, and encryption methods.\n",
      "\n",
      "- **Consumer Education and Public Engagement:** To build public confidence, active campaigns that educate potential users about the safety standards, benefits, and operational guidelines of flying cars are recommended. Transparency in testing and certification processes will enhance public trust.\n",
      "\n",
      "- **Economic Scalability:** Strategies to reduce manufacturing costs through economies of scale and technological optimizations should be a priority. Emphasis on ecological designs and sustainable production methods will further bolster the technology’s market appeal.\n",
      "\n",
      "## Conclusions\n",
      "\n",
      "The advent of flying cars marks a pivotal moment in the evolution of urban transportation. The promise of efficient, rapid transit that can alleviate congestion and shorten commute times is balanced by significant challenges. Technological innovations in propulsion, battery efficiency, and autonomous navigation are steadily addressing some of these hurdles, while evolving regulatory frameworks play a critical role in paving the way for commercial adoption.\n",
      "\n",
      "However, the successful integration of these vehicles into the urban fabric requires a comprehensive approach that encompasses policy harmonization, infrastructure development, rigorous safety standards, and public engagement. The next decade is poised to be transformative as flying cars transition from niche prototypes to potentially mainstream modes of transportation, reshaping both urban landscapes and mobility paradigms.\n",
      "\n",
      "In conclusion, while flying cars hold immense promise, their transition into widespread use remains contingent upon overcoming technological, regulatory, and societal hurdles. Future research should focus on addressing these gaps to ensure that the potential of this futuristic mobility solution is fully realized in a safe, efficient, and economically viable manner.\n",
      "\n",
      "---\n",
      "\n",
      "*References:* \n",
      "\n",
      "- AP News. (2024). *Trump's new drone orders and flying car developments*. Retrieved from [AP News](https://apnews.com/article/85fd3c8b905a003eff64590afb5da339?utm_source=openai)\n",
      "- CNN. (2023). *Alef Aeronautics Model A and FAA certification*. Retrieved from [CNN](https://www.cnn.com/2023/07/03/tech/flying-car-faa/index.html/?utm_source=openai)\n",
      "- Reuters. (2025). *Defence opportunities and flying taxis*. Retrieved from [Reuters](https://www.reuters.com/business/autos-transportation/defence-opportunity-could-finally-make-flying-taxis-reality-2025-06-20/?utm_source=openai)\n",
      "- Science News Today. (n.d.). *Safety challenges in flying cars*. Retrieved from [Science News Today](https://www.sciencenewstoday.org/are-flying-cars-safe-what-experts-say-about-the-future-of-aerial-travel?utm_source=openai)\n",
      "- Topspeed.com. (n.d.). *FAA flying car challenges and innovations*. Retrieved from [Topspeed.com](https://www.topspeed.com/faa-flying-cars/?utm_source=openai)\n",
      "- Others as cited.\n",
      "\n",
      "\n",
      "\n",
      "=====FOLLOW UP QUESTIONS=====\n",
      "\n",
      "\n",
      "1. How can advanced sensor fusion be optimized to further improve the safety and reliability of autonomous flying car navigation systems?\n",
      "2. What methodologies can be employed to harmonize international regulatory standards for eVTOLs to facilitate global market integration?\n",
      "3. In what ways can urban infrastructure planning be reimagined to accommodate dedicated vertiports and aerial traffic corridors for flying cars?\n",
      "4. What long-term environmental impact assessments are necessary to compare the carbon footprint of conventional vehicles versus electric flying cars?\n",
      "5. How can cost-reduction strategies and economies of scale be achieved to transition flying cars from luxury items to mass-market transportation solutions?\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sample Report in Markdown \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agents SDK: A Comprehensive Report\n",
    "\n",
    "*Published: October 2023*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Core Concepts and Key Features](#core-concepts-and-key-features)\n",
    "3. [Architecture and Developer Experience](#architecture-and-developer-experience)\n",
    "4. [Comparative Analysis with Alternative Frameworks](#comparative-analysis-with-alternative-frameworks)\n",
    "5. [Integrations and Real-World Applications](#integrations-and-real-world-applications)\n",
    "6. [Troubleshooting, Observability, and Debugging](#troubleshooting-observability-and-debugging)\n",
    "7. [Community Impact and Future Directions](#community-impact-and-future-directions)\n",
    "8. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In March 2025, OpenAI released the Agents SDK, a groundbreaking, open-source framework aimed at simplifying the development of autonomous AI agents capable of performing intricate tasks with minimal human intervention. Designed with a Python-first approach, the SDK offers a minimal set of abstractions, yet provides all the necessary components to build, debug, and optimize multi-agent workflows. The release marked a significant milestone for developers who seek to integrate large language models (LLMs) with advanced task delegation mechanisms, enabling next-generation automation in various industries.\n",
    "\n",
    "The primary goal of the OpenAI Agents SDK is to streamline the creation of agentic applications by offering core primitives such as *agents*, *handoffs*, and *guardrails*. These primitives are essential for orchestrating autonomous AI systems that perform key functions such as web search, file operations, and even actions on a computer. This report delves into the SDK's features, its operational architecture, integration capabilities, and how it compares to other frameworks in the rapidly evolving landscape of AI development tools.\n",
    "\n",
    "## Core Concepts and Key Features\n",
    "\n",
    "### Agents\n",
    "\n",
    "At the heart of the SDK are **agents**—intelligent entities that encapsulate a specific set of instructions and tools. Each agent is built on top of a large language model and can be customized with its own personality, domain expertise, and operational directives. For example, a \"Math Tutor\" agent could be designed to solve math problems by explaining each step clearly.\n",
    "\n",
    "**Key elements of an agent include:**\n",
    "\n",
    "- **Instructions:** Specific guidelines that shape the agent's responses and behavior in the context of its designated role.\n",
    "- **Tools:** Predefined or dynamically integrated tools that the agent can leverage to access external resources (e.g., web search or file search functionalities).\n",
    "\n",
    "### Handoffs\n",
    "\n",
    "A unique feature introduced by the SDK is the concept of **handoffs**. Handoffs allow agents to delegate tasks to one another based on expertise and contextual needs. This orchestration paves the way for sophisticated workflows where multiple agents work in tandem, each contributing its specialized capabilities to complete a complex task.\n",
    "\n",
    "### Guardrails\n",
    "\n",
    "Safety and reliability remain a cornerstone in AI development, and the SDK introduces **guardrails** as a means of controlling input and output validation. Guardrails help ensure that agents operate within defined safety parameters, preventing unintended actions and mitigating risks associated with autonomous decision-making.\n",
    "\n",
    "### Built-in Debugging and Observability\n",
    "\n",
    "The development process is further enhanced by built-in **tracing and visualization tools**. These tools offer real-time insights into agent interactions, tool invocations, and decision-making pathways, thereby making debugging and optimization more accessible and systematic. The tracing functionality is a vital feature for developers looking to fine-tune agent performance in production environments.\n",
    "\n",
    "## Architecture and Developer Experience\n",
    "\n",
    "### Python-First Approach\n",
    "\n",
    "The SDK is inherently Python-based, making it highly accessible to the vast community of Python developers. By leveraging existing language features without introducing excessive abstractions, the SDK provides both simplicity and power. The installation is straightforward:\n",
    "\n",
    "```bash\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install openai-agents\n",
    "```\n",
    "\n",
    "Once installed, developers can create and configure agents with minimal boilerplate code. The emphasis on a minimal learning curve has been a significant point of praise among early adopters.\n",
    "\n",
    "### Developer Tools and Tutorials\n",
    "\n",
    "In addition to comprehensive official documentation available on OpenAI’s GitHub pages, the community has contributed numerous tutorials and code examples. Video tutorials by experts such as Sam Witteveen and James Briggs provide hands-on demonstrations, ranging from simple agent creation to more sophisticated scenarios involving parallel execution and advanced tool integrations.\n",
    "\n",
    "### Use of Python's Ecosystem\n",
    "\n",
    "The integration with Python’s ecosystem means that developers can immediately apply a range of established libraries and frameworks. For instance, utilizing Pydantic for input validation in guardrails or leveraging visualization libraries to display agent workflows are examples of how the SDK embraces the strengths of Python.\n",
    "\n",
    "## Comparative Analysis with Alternative Frameworks\n",
    "\n",
    "While the OpenAI Agents SDK has received acclaim for its simplicity and robust integration with OpenAI’s ecosystem, other frameworks such as LangGraph, CrewAI, and AutoGen have emerged as viable alternatives. Here’s how they compare:\n",
    "\n",
    "- **LangGraph:** Known for its graph-based architecture, LangGraph is ideal for handling complex and cyclical workflows that require sophisticated state management. However, it comes with a steeper learning curve, making it less accessible for projects that require quick prototyping.\n",
    "\n",
    "- **CrewAI:** Emphasizing a role-based multi-agent system, CrewAI excels in scenarios where collaboration among agents is critical. Its design promotes clear segregation of duties among different agents, which can be beneficial in customer service or large-scale business automation.\n",
    "\n",
    "- **AutoGen:** This framework supports flexible conversation patterns and diverse agent interactions, particularly useful in applications where adaptive dialogue is essential. Nevertheless, AutoGen may introduce additional overhead when managing state and coordinating multiple agents.\n",
    "\n",
    "In contrast, the OpenAI Agents SDK strikes an effective balance by offering a lightweight yet powerful toolset geared towards production readiness. Its strengths lie in its minimal abstractions, ease of integration with various tools (like web search and file search), and built-in observability features that are crucial for debugging and tracing agent interactions.\n",
    "\n",
    "## Integrations and Real-World Applications\n",
    "\n",
    "### Diverse Integrations\n",
    "\n",
    "The real power of the OpenAI Agents SDK surfaces when it is integrated with other systems and platforms. Notable integrations include:\n",
    "\n",
    "- **Box Integration:** Enhancing enterprise content management, Box has adopted the SDK to enable secure AI-powered data processing. This integration allows agents to reliably access and interpret proprietary data.\n",
    "\n",
    "- **Coinbase AgentKit:** With financial capabilities in mind, Coinbase introduced AgentKit, leveraging the SDK to incorporate financial operations and risk analysis directly into AI agents.\n",
    "\n",
    "- **Milvus and Ollama:** These integrations allow the SDK to handle high-performance data queries and run agents on local infrastructure respectively, ensuring both speed and privacy.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "The versatility of the SDK lends itself to a multitude of applications:\n",
    "\n",
    "- **Customer Support:** Automated agents can be built to handle customer inquiries, providing faster and more accurate responses while reducing workload on human agents.\n",
    "\n",
    "- **Content Generation:** In marketing and media, agents can generate high-quality articles, detailed reports, and even code reviews with built-in content guidelines.\n",
    "\n",
    "- **Financial Analysis:** Specialized agents capable of real-time data fetching and market analysis can generate actionable insights for investors and analysts.\n",
    "\n",
    "- **Health and Wellness:** Custom agents can handle tasks such as appointment scheduling, patient record management, and even provide personalized fitness and dietary recommendations.\n",
    "\n",
    "- **Educational Tools:** Intelligent tutoring agents can assist students by providing personalized learning experiences and instant feedback on assignments.\n",
    "\n",
    "These applications underscore the SDK’s transformative potential across various industries, driving the trend towards increased automation and efficiency.\n",
    "\n",
    "## Troubleshooting, Observability, and Debugging\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "As with any cutting-edge technology, developers working with the OpenAI Agents SDK have encountered challenges:\n",
    "\n",
    "- **API Key Management:** Authentication errors due to missing or invalid API keys are common. The solution involves ensuring that the `OPENAI_API_KEY` environment variable is correctly set or programmatically configured using OpenAI’s helper functions.\n",
    "\n",
    "- **Rate Limitations:** Rate limits, an intrinsic challenge with API-based services, require developers to monitor dashboard usage and implement retry strategies with exponential backoff.\n",
    "\n",
    "- **Response Delays:** Network latency and high server loads can result in unexpected delays. Developers are advised to check network settings, adhere to best practices in setting request timeouts, and monitor OpenAI’s service status.\n",
    "\n",
    "### Built-In Tracing Capabilities\n",
    "\n",
    "The SDK provides robust tracing tools that log agent inputs, outputs, tool interactions, and error messages. This level of observability is crucial for debugging complex workflows and allows developers to visualize the agent’s decision-making process in real time. By configuring a `TracingConfig` object, developers can capture detailed insights and identify performance bottlenecks.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Prompt Engineering:** Refine prompts to reduce ambiguity and minimize unexpected outputs.\n",
    "- **Layered Validation:** Use guardrails extensively to ensure inputs and outputs are verified at multiple layers.\n",
    "- **Modular Design:** Break complex tasks into smaller, more manageable components using handoffs to delegate tasks appropriately.\n",
    "\n",
    "## Community Impact and Future Directions\n",
    "\n",
    "### Developer and Enterprise Adoption\n",
    "\n",
    "The release of the OpenAI Agents SDK has been met with enthusiasm within the developer community. Its ease of use, combined with comprehensive documentation and community-driven resources (such as tutorials on Class Central and DataCamp), has accelerated its adoption across educational, enterprise, and research sectors.\n",
    "\n",
    "Several leading organizations, including Box and Coinbase, have integrated the SDK into their workflows, demonstrating its capability to drive real-world business solutions. The open-source nature of the SDK, licensed under the MIT License, further encourages widespread industrial collaboration and innovation.\n",
    "\n",
    "### Future Prospects\n",
    "\n",
    "Looking forward, OpenAI plans to extend the SDK’s support beyond Python, potentially embracing other programming languages like JavaScript. Additionally, future updates are anticipated to expand tool integrations, further enhance safety mechanisms, and streamline the development of multi-agent ecosystems. Planned deprecations of older APIs, such as the Assistants API in favor of the more unified Responses API, underline the SDK’s evolving roadmap aimed at future-proofing agentic applications.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The OpenAI Agents SDK represents a significant step forward in the field of AI development. Its lightweight, Python-first framework facilitates the creation of autonomous agents that can handle a wide array of tasks—from simple inquiries to complex multi-agent systems. The SDK’s robust integration capabilities, combined with its focus on safety and observability, make it an ideal choice for both developers and enterprises seeking to build reliable, scalable agentic applications.\n",
    "\n",
    "In summary, the SDK not only lowers the barrier to entry for developing sophisticated AI applications but also sets the stage for further innovations as the ecosystem evolves. It is poised to become a standard toolkit for the next generation of AI-driven technologies, empowering users across sectors to achieve greater efficiency and creativity in task automation.\n",
    "\n",
    "---\n",
    "\n",
    "*For further reading, developers are encouraged to visit the official OpenAI documentation, join the community forums, and explore real-world use cases to deepen their understanding of this transformative tool.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
